#!/usr/bin/env python3
"""
æ–‡æ¡£æœåŠ¡å±‚ - å¤„ç†æ–‡æ¡£è§£æã€éªŒè¯å’Œæ‰¹é‡æ“ä½œç›¸å…³çš„ä¸šåŠ¡é€»è¾‘ï¼ˆSQLAlchemyç‰ˆæœ¬ï¼‰
"""
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from .sync_service import SyncService
from database.connection import db
from database.models import SyncRecord


class DocumentService(SyncService):
    """æ–‡æ¡£æœåŠ¡ç±» - ç»§æ‰¿åŒæ­¥æœåŠ¡çš„åŸºç¡€åŠŸèƒ½ï¼Œä¸“é—¨å¤„ç†æ–‡æ¡£ç›¸å…³æ“ä½œ"""
    
    def __init__(self, logger: logging.Logger = None):
        super().__init__(logger)
    
    def parse_document_urls(self, urls: List[str]) -> Dict[str, Any]:
        """è§£ææ–‡æ¡£URLè·å–ä¿¡æ¯"""
        try:
            if not urls:
                raise ValueError("è¯·æä¾›è¦è§£æçš„URL")
            
            document_ids = []
            parsed_results = []
            
            for url in urls:
                try:
                    # ç®€å•çš„URLè§£æé€»è¾‘
                    if 'feishu' in url or 'larksuite' in url:
                        platform = 'feishu'
                        # æå–æ–‡æ¡£IDï¼ˆç®€åŒ–ç‰ˆï¼‰
                        if '/docs/' in url:
                            doc_id = url.split('/docs/')[-1].split('?')[0].split('#')[0]
                        elif '/docx/' in url:
                            doc_id = url.split('/docx/')[-1].split('?')[0].split('#')[0]
                        else:
                            doc_id = url.split('/')[-1].split('?')[0].split('#')[0] if '/' in url else url
                    elif 'notion' in url:
                        platform = 'notion'
                        doc_id = url.split('/')[-1].split('?')[0].split('#')[0] if '/' in url else url
                    else:
                        # å¦‚æœä¸æ˜¯é“¾æ¥ï¼Œå¯èƒ½æ˜¯ç›´æ¥çš„æ–‡æ¡£ID
                        if not url.startswith('http'):
                            platform = 'feishu'  # é»˜è®¤å¹³å°
                            doc_id = url
                        else:
                            continue  # è·³è¿‡ä¸æ”¯æŒçš„URL
                    
                    # æ¸…ç†æ–‡æ¡£ID
                    doc_id = doc_id.strip()
                    if doc_id:
                        document_ids.append(doc_id)
                        parsed_results.append({
                            'url': url,
                            'platform': platform,
                            'document_id': doc_id,
                            'status': 'parsed'
                        })
                
                except Exception as e:
                    parsed_results.append({
                        'url': url,
                        'platform': 'unknown',
                        'document_id': None,
                        'status': 'error',
                        'error_message': str(e)
                    })
            
            return {
                'total_urls': len(urls),
                'parsed_count': len(document_ids),
                'document_ids': document_ids,
                'results': parsed_results
            }
            
        except Exception as e:
            self.logger.error(f"è§£ææ–‡æ¡£URLå¤±è´¥: {e}")
            raise
    
    def create_manual_sync_tasks(self, document_ids: List[str], source_platform: str = 'feishu', 
                                target_platform: str = 'notion', force_resync: bool = False, 
                                notion_category: str = None, notion_type: str = None) -> Dict[str, Any]:
        """åˆ›å»ºæ‰‹åŠ¨åŒæ­¥ä»»åŠ¡ï¼ˆç«‹å³æ‰§è¡Œï¼‰"""
        try:
            if not document_ids:
                raise ValueError("è¯·æä¾›è¦åŒæ­¥çš„æ–‡æ¡£ID")
            
            if not source_platform or not target_platform:
                raise ValueError("è¯·æä¾›æºå¹³å°å’Œç›®æ ‡å¹³å°")
            
            # éªŒè¯å¹³å°ç±»å‹
            valid_platforms = ['feishu', 'notion']
            if source_platform not in valid_platforms or target_platform not in valid_platforms:
                raise ValueError("æ— æ•ˆçš„å¹³å°ç±»å‹")
            
            created_records = []
            record_ids = []
            
            # ä½¿ç”¨æ›´å¼ºçš„å¹¶å‘æ§åˆ¶ç­–ç•¥é˜²æ­¢é‡å¤è®°å½•
            import time
            import random
            from datetime import datetime, timedelta
            
            for doc_id in document_ids:
                # æ·»åŠ éšæœºå»¶è¿Ÿé¿å…å®Œå…¨åŒæ—¶çš„è¯·æ±‚
                time.sleep(random.uniform(0.01, 0.05))
                
                # é‡è¯•æœºåˆ¶
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        with db.get_session() as session:
                            # æ£€æŸ¥æœ€è¿‘10ç§’å†…æ˜¯å¦å·²æœ‰åŒæ ·çš„åŒæ­¥è®°å½•
                            cutoff_time = datetime.now() - timedelta(seconds=10)
                            existing_record = session.query(SyncRecord).filter(
                                SyncRecord.source_platform == source_platform,
                                SyncRecord.target_platform == target_platform,
                                SyncRecord.source_id == doc_id,
                                SyncRecord.sync_status.in_(['pending', 'processing']),
                                SyncRecord.created_at >= cutoff_time
                            ).first()
                            
                            if existing_record and not force_resync:
                                self.logger.info(f"æ–‡æ¡£ {doc_id} åœ¨æœ€è¿‘10ç§’å†…å·²æœ‰åŒæ­¥ä»»åŠ¡: {existing_record.record_number}")
                                record_ids.append(existing_record.id)
                                created_records.append({
                                    "record_number": existing_record.record_number,
                                    "document_id": doc_id,
                                    "record_id": existing_record.id,
                                    "status": "existing"
                                })
                                break  # è·³å‡ºé‡è¯•å¾ªç¯
                            
                            record_number = self.generate_record_number()
                            
                            # åˆ›å»ºåŒæ­¥è®°å½•
                            new_record = SyncRecord(
                                record_number=record_number,
                                source_platform=source_platform,
                                target_platform=target_platform,
                                source_id=doc_id,
                                sync_status='processing'
                            )
                            
                            session.add(new_record)
                            session.commit()
                            
                            # åˆ›å»ºæˆåŠŸåå†æ¬¡æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
                            time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…å…¶ä»–å¯èƒ½çš„å¹¶å‘è¯·æ±‚
                            duplicate_records = session.query(SyncRecord).filter(
                                SyncRecord.source_platform == source_platform,
                                SyncRecord.target_platform == target_platform,
                                SyncRecord.source_id == doc_id,
                                SyncRecord.sync_status == 'processing',
                                SyncRecord.created_at >= cutoff_time
                            ).order_by(SyncRecord.created_at).all()
                            
                            if len(duplicate_records) > 1:
                                # å¦‚æœæœ‰é‡å¤ï¼Œä¿ç•™æœ€æ—©çš„ï¼Œåˆ é™¤ååˆ›å»ºçš„
                                records_to_delete = duplicate_records[1:]
                                for dup_record in records_to_delete:
                                    if dup_record.id == new_record.id:
                                        # å½“å‰åˆ›å»ºçš„è®°å½•æ˜¯é‡å¤çš„ï¼Œåˆ é™¤å®ƒå¹¶ä½¿ç”¨æœ€æ—©çš„è®°å½•
                                        session.delete(new_record)
                                        session.commit()
                                        earliest_record = duplicate_records[0]
                                        self.logger.warning(f"åˆ é™¤é‡å¤è®°å½• {new_record.record_number}ï¼Œä½¿ç”¨å·²å­˜åœ¨è®°å½• {earliest_record.record_number}")
                                        record_ids.append(earliest_record.id)
                                        created_records.append({
                                            "record_number": earliest_record.record_number,
                                            "document_id": doc_id,
                                            "record_id": earliest_record.id,
                                            "status": "existing"
                                        })
                                        break
                            else:
                                # æ²¡æœ‰é‡å¤ï¼Œä½¿ç”¨æ–°åˆ›å»ºçš„è®°å½•
                                record_id = new_record.id
                                record_ids.append(record_id)
                                created_records.append({
                                    "record_number": record_number,
                                    "document_id": doc_id,
                                    "record_id": record_id,
                                    "status": "created"
                                })
                            break  # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                            
                    except Exception as e:
                        if attempt < max_retries - 1:
                            self.logger.warning(f"æ–‡æ¡£ {doc_id} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}ï¼Œç­‰å¾…é‡è¯•...")
                            time.sleep(random.uniform(0.1, 0.3))
                            continue
                        else:
                            self.logger.error(f"æ–‡æ¡£ {doc_id} æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥: {e}")
                            raise e
            
            # ç«‹å³è§¦å‘åŒæ­¥å¤„ç†
            successful_syncs = 0
            failed_syncs = 0
            
            for i, record_id in enumerate(record_ids):
                try:
                    # è°ƒç”¨åŒæ­¥å¤„ç†å™¨
                    self._execute_sync_immediately(record_id, source_platform, target_platform, document_ids[i], notion_category, notion_type)
                    successful_syncs += 1
                except Exception as sync_error:
                    self.logger.error(f"åŒæ­¥è®°å½• {record_id} æ‰§è¡Œå¤±è´¥: {sync_error}")
                    failed_syncs += 1
                    # æ›´æ–°è®°å½•çŠ¶æ€ä¸ºå¤±è´¥
                    self._update_sync_status(record_id, 'failed', str(sync_error))
            
            # ç»Ÿè®¡åˆ›å»ºå’Œç°æœ‰è®°å½•
            new_records_count = len([r for r in created_records if r.get('status') != 'existing'])
            existing_records_count = len([r for r in created_records if r.get('status') == 'existing'])
            
            message_parts = []
            if new_records_count > 0:
                message_parts.append(f"åˆ›å»º {new_records_count} ä¸ªæ–°ä»»åŠ¡")
            if existing_records_count > 0:
                message_parts.append(f"è·³è¿‡ {existing_records_count} ä¸ªå·²å­˜åœ¨ä»»åŠ¡")
            
            message = f"å¤„ç†å®Œæˆï¼š{', '.join(message_parts)}ï¼ˆæˆåŠŸ: {successful_syncs}, å¤±è´¥: {failed_syncs}ï¼‰"
            
            return {
                "message": message,
                "created_records": created_records,
                "total_processed": len(created_records),
                "new_records": new_records_count,
                "existing_records": existing_records_count,
                "successful_syncs": successful_syncs,
                "failed_syncs": failed_syncs
            }
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ‰‹åŠ¨åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def _execute_sync_immediately(self, record_id: int, source_platform: str, target_platform: str, document_id: str, notion_category: str = None, notion_type: str = None):
        """ç«‹å³æ‰§è¡ŒåŒæ­¥ä»»åŠ¡"""
        try:
            if source_platform == 'feishu' and target_platform == 'notion':
                result = self._sync_feishu_to_notion(document_id, record_id, notion_category, notion_type)
            elif source_platform == 'notion' and target_platform == 'feishu':
                result = self._sync_notion_to_feishu(document_id, record_id)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„åŒæ­¥æ–¹å‘: {source_platform} -> {target_platform}")
            
            if result.get('success'):
                self._update_sync_status(record_id, 'completed', result.get('message'))
                if result.get('target_id'):
                    self._update_target_id(record_id, result['target_id'])
            else:
                self._update_sync_status(record_id, 'failed', result.get('message'))
                
        except Exception as e:
            self.logger.error(f"æ‰§è¡ŒåŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def _sync_feishu_to_notion(self, feishu_doc_id: str, record_id: int, notion_category: str = None, notion_type: str = None) -> Dict[str, Any]:
        """å°†é£ä¹¦æ–‡æ¡£åŒæ­¥åˆ°Notion"""
        try:
            # å¯¼å…¥å®¢æˆ·ç«¯
            from app.services.feishu_client import FeishuClient
            from app.services.notion_client import NotionClient
            
            feishu_client = FeishuClient(logger=self.logger)
            notion_client = NotionClient()
            
            # 1. ä»é£ä¹¦è·å–æ–‡æ¡£å†…å®¹
            self.logger.info(f"æ­£åœ¨ä»é£ä¹¦è·å–æ–‡æ¡£å†…å®¹: {feishu_doc_id}")
            
            # å¦‚æœæ˜¯æµ‹è¯•æ–‡æ¡£IDï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            if feishu_doc_id.startswith("test_"):
                self.logger.info("ä½¿ç”¨æµ‹è¯•æ¨¡æ‹Ÿæ•°æ®è¿›è¡ŒåŒæ­¥")
                feishu_content = {
                    "title": f"æµ‹è¯•æ–‡æ¡£ - {feishu_doc_id}",
                    "content": [
                        {
                            "type": "paragraph",
                            "text": f"è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•åŒæ­¥æ–‡æ¡£ï¼Œæ–‡æ¡£ID: {feishu_doc_id}"
                        },
                        {
                            "type": "paragraph", 
                            "text": "æµ‹è¯•å†…å®¹ï¼šæ‰‹åŠ¨åŒæ­¥åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼"
                        }
                    ],
                    "document_id": feishu_doc_id
                }
            else:
                feishu_content = feishu_client.parse_document_content(feishu_doc_id)
                
                if not feishu_content:
                    raise Exception("æ— æ³•è·å–é£ä¹¦æ–‡æ¡£å†…å®¹")
            
            # 2. ä½¿ç”¨é…ç½®çš„å›ºå®šNotionæ•°æ®åº“è¿›è¡ŒåŒæ­¥
            from config.settings import settings
            target_notion_id = settings.notion_test_page_id or settings.notion_database_id
            
            if not target_notion_id:
                raise Exception("æœªé…ç½®ç›®æ ‡Notionæ•°æ®åº“IDï¼Œè¯·æ£€æŸ¥NOTION_TEST_PAGE_IDæˆ–NOTION_DATABASE_IDç¯å¢ƒå˜é‡")
            
            # è½¬æ¢Notion IDæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if len(target_notion_id) == 32 and "-" not in target_notion_id:
                # å°†32ä½å­—ç¬¦IDè½¬æ¢ä¸ºå¸¦è¿å­—ç¬¦çš„æ ¼å¼ï¼šxxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
                target_notion_id = f"{target_notion_id[:8]}-{target_notion_id[8:12]}-{target_notion_id[12:16]}-{target_notion_id[16:20]}-{target_notion_id[20:]}"
                self.logger.info(f"è½¬æ¢æ•°æ®åº“IDæ ¼å¼: {target_notion_id}")
            
            # 3. æ£€æŸ¥Notionæ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨åŒæ ‡é¢˜é¡µé¢
            title = feishu_content.get('title', f'åŒæ­¥æ–‡æ¡£ - {feishu_doc_id}')
            
            # å…ˆæŸ¥æ‰¾æ˜¯å¦å­˜åœ¨åŒæ ‡é¢˜çš„é¡µé¢
            existing_page = notion_client.find_page_in_database_by_title(target_notion_id, title)
            
            if existing_page:
                existing_page_id = existing_page['id']
                self.logger.info(f"å‘ç°å·²å­˜åœ¨åŒæ ‡é¢˜é¡µé¢ï¼Œæ›´æ–°ç°æœ‰é¡µé¢: {existing_page_id}")
                
                # æ›´æ–°ç°æœ‰é¡µé¢è€Œä¸æ˜¯åˆ›å»ºæ–°é¡µé¢
                content_blocks = []
            else:
                # åˆ›å»ºæ–°é¡µé¢
                self.logger.info(f"åœ¨Notionæ•°æ®åº“ä¸­åˆ›å»ºæ–°é¡µé¢: {target_notion_id}")
                content_blocks = []
            
            # Convert feishu content to Notion blocks
            document_title = feishu_content.get('title', '')
            for block in feishu_content.get('blocks', []):
                block_type = block.get('type')
                block_content = block.get('content', '')
                
                # è·³è¿‡ç©ºå†…å®¹çš„å—
                if not block_content and block_type not in ['image']:
                    continue
                
                # è·³è¿‡ä¸æ–‡æ¡£æ ‡é¢˜é‡å¤çš„heading1å—ï¼Œé¿å…é‡å¤æ ‡é¢˜
                if block_type == 'heading1' and block_content and block_content.strip() == document_title.strip():
                    continue
                
                if block_type in ['text']:
                    content_blocks.append({
                        "object": "block",
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{
                                "type": "text",
                                "text": {
                                    "content": block_content
                                }
                            }]
                        }
                    })
                elif block_type in ['heading1', 'heading2', 'heading3']:
                    # å¤„ç†æ ‡é¢˜å—
                    heading_level = block.get('level', 1)
                    heading_type = f"heading_{min(heading_level, 3)}"  # Notionæœ€å¤šæ”¯æŒ3çº§æ ‡é¢˜
                    content_blocks.append({
                        "object": "block",
                        "type": heading_type,
                        heading_type: {
                            "rich_text": [{
                                "type": "text",
                                "text": {
                                    "content": block_content
                                }
                            }]
                        }
                    })
                elif block_type == 'code':
                    # å¤„ç†ä»£ç å—
                    language = block.get('language', 'plain_text')
                    # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œæ·»åŠ å ä½ç¬¦
                    code_content = block_content if block_content else "# ä»£ç å†…å®¹"
                    content_blocks.append({
                        "object": "block",
                        "type": "code",
                        "code": {
                            "rich_text": [{
                                "type": "text",
                                "text": {
                                    "content": code_content
                                }
                            }],
                            "language": language
                        }
                    })
                elif block_type == 'image':
                    # å¤„ç†å›¾ç‰‡å—ï¼Œå…ˆä¸Šä¼ åˆ°ä¸ƒç‰›äº‘å†åˆ›å»ºNotionå›¾ç‰‡å—
                    file_token = block.get('file_token', '')
                    alt_text = block.get('alt_text', '')
                    if file_token:
                        try:
                            # å¯¼å…¥ä¸ƒç‰›äº‘å®¢æˆ·ç«¯
                            from app.services.qiniu_client import QiniuClient
                            qiniu_client = QiniuClient()
                            
                            # ä¸Šä¼ å›¾ç‰‡åˆ°ä¸ƒç‰›äº‘
                            cdn_url, file_hash, file_size = qiniu_client.download_from_feishu_and_upload(
                                feishu_client, file_token
                            )
                            
                            # åˆ›å»ºçœŸæ­£çš„Notionå›¾ç‰‡å—
                            content_blocks.append({
                                "object": "block",
                                "type": "image",
                                "image": {
                                    "type": "external",
                                    "external": {
                                        "url": cdn_url
                                    },
                                    "caption": [
                                        {
                                            "type": "text",
                                            "text": {
                                                "content": alt_text or "å›¾ç‰‡"
                                            }
                                        }
                                    ] if alt_text else []
                                }
                            })
                            
                            self.logger.info(f"æˆåŠŸå¤„ç†å›¾ç‰‡: {file_token} -> {cdn_url}")
                            
                        except Exception as e:
                            self.logger.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥ {file_token}: {e}")
                            # å¦‚æœå›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œåˆ›å»ºå ä½ç¬¦
                            content_blocks.append({
                                "object": "block",
                                "type": "paragraph",
                                "paragraph": {
                                    "rich_text": [{
                                        "type": "text",
                                        "text": {
                                            "content": f"ğŸ–¼ï¸ å›¾ç‰‡å¤„ç†å¤±è´¥ ({alt_text})\né”™è¯¯: {str(e)}"
                                        }
                                    }]
                                }
                            })
                else:
                    # å…¶ä»–ç±»å‹éƒ½å½“ä½œæ®µè½å¤„ç†
                    content_blocks.append({
                        "object": "block",
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{
                                "type": "text",
                                "text": {
                                    "content": block_content or f"[{block_type}å†…å®¹]"
                                }
                            }]
                        }
                    })
            
            # æ³¨é‡Šæ‰æºæ–‡æ¡£æ—¶é—´æˆ³å’Œæ¥æºä¿¡æ¯ï¼Œä¿æŒæ–‡æ¡£å†…å®¹å¹²å‡€
            # å¦‚æœéœ€è¦æ˜¾ç¤ºæ¥æºä¿¡æ¯ï¼Œå¯ä»¥åœ¨è¿™é‡Œé‡æ–°å¯ç”¨
            # from datetime import datetime
            # timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            # content_blocks.append({
            #     "object": "block",
            #     "type": "paragraph", 
            #     "paragraph": {
            #         "rich_text": [{
            #             "type": "text",
            #             "text": {
            #                 "content": f"åŒæ­¥æ—¶é—´: {timestamp} | æ¥æº: é£ä¹¦æ–‡æ¡£ {feishu_doc_id}"
            #             },
            #             "annotations": {
            #                 "italic": True,
            #                 "color": "gray"
            #             }
            #         }]
            #     }
            # })
            
            if existing_page:
                # æ›´æ–°ç°æœ‰é¡µé¢
                try:
                    update_result = notion_client.update_page_from_feishu(existing_page_id, feishu_content)
                    self.logger.info(f"æˆåŠŸæ›´æ–°ç°æœ‰Notioné¡µé¢: {existing_page_id}")
                    
                    # æ›´æ–°åŒæ­¥è®°å½•çš„target_id
                    from database.connection import db
                    from database.models import SyncRecord
                    with db.get_session() as session:
                        sync_record = session.query(SyncRecord).filter(SyncRecord.id == record_id).first()
                        if sync_record:
                            sync_record.target_id = existing_page_id
                            sync_record.updated_at = datetime.now()
                            session.commit()
                    
                    return {
                        'success': True,
                        'message': f"æˆåŠŸæ›´æ–°é£ä¹¦æ–‡æ¡£ {feishu_doc_id} åˆ°ç°æœ‰Notioné¡µé¢",
                        'target_id': existing_page_id,
                        'action': 'updated'
                    }
                except Exception as e:
                    self.logger.warning(f"æ›´æ–°ç°æœ‰é¡µé¢å¤±è´¥: {e}, å°†åˆ›å»ºæ–°é¡µé¢")
                    # å¦‚æœæ›´æ–°å¤±è´¥ï¼Œç»§ç»­åˆ›å»ºæ–°é¡µé¢
            
            # åˆ›å»ºæ–°é¡µé¢
            self.logger.info(f"åœ¨æ•°æ®åº“ {target_notion_id} ä¸­åˆ›å»ºæ–°é¡µé¢ï¼Œæ ‡é¢˜: {title}")
            
            # ä¸ºæ•°æ®åº“é¡µé¢åˆ›å»ºå±æ€§
            properties = {
                "title": {
                    "title": [
                        {
                            "text": {
                                "content": title
                            }
                        }
                    ]
                },
                "type": {
                    "select": {
                        "name": notion_type or "Post"
                    }
                },
                "status": {
                    "select": {
                        "name": "Draft"
                    }
                },
                "category": {
                    "select": {
                        "name": notion_category or "æŠ€æœ¯åˆ†äº«"
                    }
                },
                "date": {
                    "date": {
                        "start": datetime.now().date().isoformat()
                    }
                }
            }
            
            # åˆ›å»ºé¡µé¢
            notion_result = notion_client.create_database_page(target_notion_id, properties, content_blocks)
            notion_result['action'] = 'created'
            
            if notion_result.get('id'):
                target_notion_id = notion_result['id']
                notion_result['success'] = True
                notion_result['page_id'] = target_notion_id
            else:
                notion_result['success'] = False
            
            if not notion_result.get('success'):
                raise Exception(f"Notionæ“ä½œå¤±è´¥: {notion_result.get('error')}")
            
            self.logger.info(f"æˆåŠŸåŒæ­¥åˆ°Notioné¡µé¢: {target_notion_id}")
            
            return {
                'success': True,
                'message': f"æˆåŠŸåŒæ­¥é£ä¹¦æ–‡æ¡£ {feishu_doc_id} åˆ° Notion",
                'target_id': target_notion_id
            }
            
        except Exception as e:
            self.logger.error(f"é£ä¹¦åˆ°NotionåŒæ­¥å¤±è´¥: {e}")
            raise
    
    def _sync_notion_to_feishu(self, notion_page_id: str, record_id: int) -> Dict[str, Any]:
        """å°†Notioné¡µé¢åŒæ­¥åˆ°é£ä¹¦ï¼ˆæš‚æœªå®ç°ï¼‰"""
        try:
            # è¿™æ˜¯ä¸€ä¸ªå ä½ç¬¦å®ç°
            self.logger.info(f"Notionåˆ°é£ä¹¦çš„åŒæ­¥æš‚æœªå®Œå…¨å®ç°: {notion_page_id}")
            return {
                'success': True,
                'message': f"Notioné¡µé¢ {notion_page_id} åŒæ­¥è¯·æ±‚å·²è®°å½•ï¼ˆåŠŸèƒ½å¼€å‘ä¸­ï¼‰",
                'target_id': None
            }
            
        except Exception as e:
            self.logger.error(f"Notionåˆ°é£ä¹¦åŒæ­¥å¤±è´¥: {e}")
            raise
    
    def _update_sync_status(self, record_id: int, status: str, message: str = None):
        """æ›´æ–°åŒæ­¥è®°å½•çŠ¶æ€"""
        try:
            with db.get_session() as session:
                record = session.query(SyncRecord).filter(SyncRecord.id == record_id).first()
                if record:
                    record.sync_status = status
                    if message:
                        record.error_message = message
                    session.commit()
        except Exception as e:
            self.logger.error(f"æ›´æ–°åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
    
    def _update_target_id(self, record_id: int, target_id: str):
        """æ›´æ–°ç›®æ ‡ID"""
        try:
            with db.get_session() as session:
                record = session.query(SyncRecord).filter(SyncRecord.id == record_id).first()
                if record:
                    record.target_id = target_id
                    session.commit()
        except Exception as e:
            self.logger.error(f"æ›´æ–°ç›®æ ‡IDå¤±è´¥: {e}")
    
    def trigger_single_sync(self, document_id: str, source_platform: str = 'feishu', 
                           target_platform: str = 'notion') -> Dict[str, Any]:
        """è§¦å‘å•ä¸ªæ–‡æ¡£åŒæ­¥"""
        try:
            if not document_id:
                raise ValueError("è¯·æä¾›æ–‡æ¡£ID")
            
            # åˆ›å»ºåŒæ­¥è®°å½•
            record_number = self.generate_record_number()
            
            with db.get_session() as session:
                new_record = SyncRecord(
                    record_number=record_number,
                    source_platform=source_platform,
                    target_platform=target_platform,
                    source_id=document_id,
                    sync_status='pending'
                )
                
                session.add(new_record)
                session.commit()
                
                record_id = new_record.id
            
            self.logger.info(f"å·²åˆ›å»ºåŒæ­¥ä»»åŠ¡: {record_number}")
            
            return {
                'success': True,
                'message': f"åŒæ­¥ä»»åŠ¡å·²åˆ›å»º: {record_number}",
                'record_id': record_id,
                'record_number': record_number
            }
            
        except Exception as e:
            self.logger.error(f"è§¦å‘å•ä¸ªåŒæ­¥å¤±è´¥: {e}")
            raise
    
    def extract_folder_id_from_url(self, folder_path: str) -> str:
        """ä»é£ä¹¦æ–‡ä»¶å¤¹URLä¸­æå–folder_id"""
        try:
            folder_id = folder_path
            if '/folder/' in folder_path:
                try:
                    folder_id = folder_path.split('/folder/')[1].split('?')[0]
                except:
                    raise ValueError("æ— æ•ˆçš„æ–‡ä»¶å¤¹é“¾æ¥æ ¼å¼")
            
            if not folder_id:
                raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„æ–‡ä»¶å¤¹é“¾æ¥")
            
            return folder_id
        except Exception as e:
            self.logger.error(f"æå–æ–‡ä»¶å¤¹IDå¤±è´¥: {e}")
            raise
    
    def scan_feishu_folder(self, folder_id: str, max_depth: int = 2, use_cache: bool = True) -> Dict[str, Any]:
        """æ‰«æé£ä¹¦æ–‡ä»¶å¤¹è·å–æ–‡æ¡£åˆ—è¡¨"""
        try:
            if not folder_id:
                raise ValueError("è¯·æä¾›æœ‰æ•ˆçš„æ–‡ä»¶å¤¹ID")
            
            self.logger.info(f"å¼€å§‹æ‰«ææ–‡ä»¶å¤¹: {folder_id}, æ·±åº¦: {max_depth}")
            
            try:
                # æ£€æŸ¥é£ä¹¦APIé…ç½®
                import os
                if not os.getenv('FEISHU_APP_ID') or not os.getenv('FEISHU_APP_SECRET'):
                    missing_configs = []
                    if not os.getenv('FEISHU_APP_ID'):
                        missing_configs.append("FEISHU_APP_ID")
                    if not os.getenv('FEISHU_APP_SECRET'):
                        missing_configs.append("FEISHU_APP_SECRET")
                    raise ValueError(f"é£ä¹¦APIæœªé…ç½®ã€‚ç¼ºå°‘é…ç½®: {', '.join(missing_configs)}")
                
                # ä½¿ç”¨çœŸå®çš„é£ä¹¦å®¢æˆ·ç«¯è·å–æ–‡æ¡£
                from app.services.feishu_client import FeishuClient
                feishu_client = FeishuClient(logger=self.logger)
                all_documents = feishu_client.get_folder_documents_with_cache(
                    folder_id, use_cache=use_cache, max_depth=max_depth
                )
                
                # ç»Ÿè®¡æ–‡æ¡£ç±»å‹
                type_stats = {}
                for doc in all_documents:
                    doc_type = doc.get("type", "unknown")
                    type_stats[doc_type] = type_stats.get(doc_type, 0) + 1
                
                # è®¡ç®—åŒæ­¥çŠ¶æ€ç»Ÿè®¡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå‡è®¾æ‰€æœ‰æ–‡æ¡£éƒ½æœªå¯ç”¨åŒæ­¥ï¼‰
                sync_enabled_count = 0
                
                return {
                    "folder_id": folder_id,
                    "total_documents": len(all_documents),
                    "type_statistics": type_stats,
                    "sync_enabled_count": sync_enabled_count,
                    "sync_disabled_count": len(all_documents) - sync_enabled_count,
                    "settings": {
                        "max_depth": max_depth,
                        "use_cache": use_cache
                    },
                    "documents": [
                        {
                            "id": doc.get("token"),  # ä½¿ç”¨tokenä½œä¸ºid
                            "name": doc.get("name"),
                            "type": doc.get("type"),
                            "token": doc.get("token"),
                            "size": doc.get("size", 0),
                            "created_time": doc.get("created_time"),
                            "modified_time": doc.get("modified_time"),
                            "sync_enabled": False  # ç®€åŒ–ç‰ˆæœ¬ï¼Œé»˜è®¤ä¸ºfalse
                        }
                        for doc in all_documents
                    ]
                }
                
            except Exception as api_error:
                self.logger.error(f"ä»é£ä¹¦è·å–æ–‡ä»¶å¤¹ '{folder_id}' å†…å®¹å¤±è´¥: {api_error}")
                
                error_msg = str(api_error)
                if "401" in error_msg or "Unauthorized" in error_msg:
                    raise ValueError("é£ä¹¦APIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥åº”ç”¨å‡­æ®é…ç½®")
                elif "403" in error_msg or "Forbidden" in error_msg:
                    raise ValueError("æ— æƒé™è®¿é—®è¯¥æ–‡ä»¶å¤¹ï¼Œè¯·æ£€æŸ¥é£ä¹¦åº”ç”¨æƒé™æˆ–è”ç³»ç®¡ç†å‘˜")
                elif "404" in error_msg or "Not Found" in error_msg:
                    raise ValueError("æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å¤¹é“¾æ¥æ˜¯å¦æ­£ç¡®")
                elif "429" in error_msg or "Too Many Requests" in error_msg:
                    raise ValueError("APIè°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•")
                else:
                    raise ValueError(f"è·å–æ–‡ä»¶å¤¹å†…å®¹å¤±è´¥: {api_error}")
            
        except Exception as e:
            self.logger.error(f"æ‰«ææ–‡ä»¶å¤¹å¤±è´¥: {e}")
            raise